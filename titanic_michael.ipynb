{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Project - Work in Progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finished Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from os.path import join\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def find(s, ch):\n",
    "    return np.array([i for i, ltr in enumerate(s) if ltr == ch]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataframe\n",
    "def load():\n",
    "    \n",
    "    # Reading data into dataframe\n",
    "    df = pd.read_csv('train.csv')\n",
    "    df = df.rename(columns = {c:c.lower() for c in df.columns})\n",
    "    \n",
    "    # Sorting gender column\n",
    "    if 'male' in df['sex'].values:\n",
    "        df['sex'] = (df['sex']=='male').astype(int).values\n",
    "    \n",
    "    # Sorting df['age'] containing string 'Master' in column 'name' NaN values\n",
    "    masterAge_mean = df['age'].loc[df['name'].str.contains('Master')].mean()\n",
    "    masterAge_mean = round(masterAge_mean, 2)\n",
    "    df['age'].loc[df['name'].str.contains('Master')] = df['age'].loc[df['name'].str.contains('Master')].fillna(masterAge_mean)\n",
    "    \n",
    "#     Sorting cabin column\n",
    "#     cabin_letters=['A','B','C','D','E','F','G']\n",
    "#     for letter in cabin_letters:\n",
    "#         df[f'cabin_{letter}'] = df['cabin'].apply(lambda x: type(x)==type('') and letter in x) \n",
    "#         df[f'cabin_{letter}'] = df[f'cabin_{letter}'].astype(int)\n",
    "#     df['cabin_number'] = df['cabin'].apply(lambda x: re.findall(r'[0-9]+', x) if type(x)==type('') else [np.nan]) \n",
    "#     df['cabin_number'] = df['cabin_number'].apply(lambda x: x[0] if len(x)>0 else np.nan) \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex   age  sibsp  parch     fare  embarked_C  embarked_Q  embarked_S  \\\n",
       "0    1  22.0      1      0   7.2500           0           0           1   \n",
       "1    0  38.0      1      0  71.2833           1           0           0   \n",
       "2    0  26.0      0      0   7.9250           0           0           1   \n",
       "3    0  35.0      1      0  53.1000           0           0           1   \n",
       "4    1  35.0      0      0   8.0500           0           0           1   \n",
       "\n",
       "   pclass_1  pclass_2  pclass_3  survived  \n",
       "0         0         0         1         0  \n",
       "1         1         0         0         1  \n",
       "2         0         0         1         1  \n",
       "3         1         0         0         1  \n",
       "4         0         0         1         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and displaying data\n",
    "df = load()\n",
    "\n",
    "# One-hot encoding 'embarked', 'pclass' columns\n",
    "# Embarked column\n",
    "df_embarked   = pd.get_dummies(df.embarked)\n",
    "embarked_cols = list(df_embarked.columns)\n",
    "df_embarked = df_embarked.rename(columns = {c: f'embarked_{c}' for c in embarked_cols})\n",
    "\n",
    "# pclass column\n",
    "df_pclass   = pd.get_dummies(df.pclass)\n",
    "pclass_cols = list(df_pclass.columns)\n",
    "df_pclass   = df_pclass.rename(columns = {c: f'pclass_{c}' for c in pclass_cols})\n",
    "\n",
    "# Removing unnecessary columns\n",
    "removed_cols = ['name','passengerid','ticket','embarked','pclass','cabin', 'cabin_number','survived']\n",
    "df = pd.concat([df, df_embarked, df_pclass], axis=1)\n",
    "df = df[[c for c in df if c not in removed_cols] + ['survived']]\n",
    "\n",
    "\n",
    "# Displaying data\n",
    "df.head()\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature age is 19.4 percent NaN values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Isolating features containing NaNs\n",
    "nan_features = []\n",
    "for c in df.columns:\n",
    "    if df[c].isnull().values.any(): \n",
    "        nan_features.append(c)\n",
    "\n",
    "# Percentage of NaNs for each column with NaNs\n",
    "for f in nan_features:\n",
    "    nan_percent = 100*df[f].isnull().sum() /len(df)\n",
    "    print('The feature',f,f'is {nan_percent:.3} percent NaN values\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NaNs to other values\n",
    "def sortnans(dftr, dfcv, mode = 'zero'):\n",
    "    if mode=='zero':\n",
    "        dftr = dftr.fillna(0)\n",
    "        dfcv = dfcv.fillna(0)\n",
    "    # Calculating the mean for features that can be and replacing NaNs with the mean\n",
    "    if mode=='mean':\n",
    "        for nf in nan_features:\n",
    "            if df[nf].dtype==('int64') or df[nf].dtype==('float64'):\n",
    "                # Mean of the nf column in training dataframe (don't use cv dataframe as this fits data to cv data)\n",
    "                mean   = dftr[nf].mean()\n",
    "                # New columns with NaNs=mean\n",
    "                newCol_tr = dftr[nf].fillna(mean) \n",
    "                newCol_cv = dfcv[nf].fillna(mean)\n",
    "                # Replace old cols containing NaNs\n",
    "                dftr.loc[:,nf] = newCol_tr\n",
    "                dfcv.loc[:,nf] = newCol_cv\n",
    "    \n",
    "    return dftr, dfcv\n",
    "\n",
    "# Processing dataframe\n",
    "def process(df, sortnan_mode):\n",
    "    \n",
    "    dftr = df[:int(len(df)*.75)] \n",
    "    dfcv = df[int(len(df)*.75):]\n",
    "    \n",
    "    dftr, dfcv = sortnans(dftr,dfcv,mode=sortnan_mode)\n",
    "    \n",
    "    features = df.columns[:-1]\n",
    "    \n",
    "    return dftr, dfcv, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "# Training and cross validation data and features\n",
    "dftr_zero, dfcv_zero, features = process(df, sortnan_mode = 'zero')\n",
    "dftr_mean, dfcv_mean, features = process(df, sortnan_mode = 'mean')\n",
    "\n",
    "# Features but removing final 3 columns\n",
    "#features = features[:-3]\n",
    "\n",
    "# X training data\n",
    "Xtr_zero = dftr_zero[features].values\n",
    "Xtr_mean = dftr_mean[features].values\n",
    "# X cross validation data\n",
    "Xcv_zero = dfcv_zero[features].values\n",
    "Xcv_mean = dfcv_mean[features].values\n",
    "\n",
    "# X data dictionary\n",
    "X_modes = {\n",
    "    'Zero': [Xtr_zero,Xcv_zero],\n",
    "    'Mean': [Xtr_mean,Xcv_mean]}\n",
    "\n",
    "# y outputs (dftr_mean=dftr_zero and dfcv_mean=dfcv_zero as these values aren't changed by sorting nans)\n",
    "ytr = dftr_mean['survived'].values\n",
    "ycv = dfcv_mean['survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating models\n",
    "model_rf = RandomForestClassifier()\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_lr = LogisticRegression(max_iter=1e5)\n",
    "\n",
    "# Models dictionary\n",
    "models = {\n",
    "    'Random Forest': model_rf,\n",
    "    'Gradient Boosting': model_gb,\n",
    "    'Logistic Regression': model_lr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier():\n",
      "Using NaN=Zero:\n",
      " accuracy:0.807175\n",
      " F1 score:0.739394\n",
      "Using NaN=Mean:\n",
      " accuracy:0.834081\n",
      " F1 score:0.775758\n",
      "\n",
      "\n",
      "GradientBoostingClassifier():\n",
      "Using NaN=Zero:\n",
      " accuracy:0.856502\n",
      " F1 score:0.789474\n",
      "Using NaN=Mean:\n",
      " accuracy:0.852018\n",
      " F1 score:0.792453\n",
      "\n",
      "\n",
      "LogisticRegression(max_iter=100000.0):\n",
      "Using NaN=Zero:\n",
      " accuracy:0.807175\n",
      " F1 score:0.715232\n",
      "Using NaN=Mean:\n",
      " accuracy:0.829596\n",
      " F1 score:0.75\n",
      "\n",
      "\n",
      "Mode: Mean\n",
      "Model: Gradient Boosting\n",
      "Best f1 score: 0.792453\n"
     ]
    }
   ],
   "source": [
    "def results(models, X_modes, ytr, ycv):\n",
    "    \n",
    "    # Best f1 score\n",
    "    f1_best=0\n",
    "    \n",
    "    # Looping through each model\n",
    "    for m in models.keys():\n",
    "        model=models[m]\n",
    "        print(f'{model}:')\n",
    "        \n",
    "        # Looping through each set of X data\n",
    "        for x in X_modes.keys():\n",
    "            X = X_modes[x][0]\n",
    "            y = ytr\n",
    "            model.fit(X,y)\n",
    "            \n",
    "            # Evaluation metrics\n",
    "            y_pred = model.predict(X_modes[x][1])\n",
    "            acc    = accuracy_score(y_pred,ycv)\n",
    "            f1     = f1_score(y_pred,ycv)\n",
    "            if f1 > f1_best:\n",
    "                f1_best   = f1\n",
    "                model_idx = m\n",
    "                X_idx     = x\n",
    "        \n",
    "            print(f'Using NaN={x}:\\n accuracy:{acc:.6}\\n F1 score:{f1:.6}')\n",
    "        print('\\n')\n",
    "    \n",
    "    return f1_best, model_idx, X_idx\n",
    "\n",
    "f1_best, model_idx, X_idx = results(models, X_modes, ytr, ycv)\n",
    "print(f'Mode: {X_idx}\\nModel: {model_idx}\\nBest f1 score: {f1_best:.6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step and Ideas: Implementing feature 'Cabin'\n",
    "\n",
    "I have researched cabins (A-F) and ranked them in order of price and status. Then depending on the pclass (1st,2nd,3rd) and fare (£(continuous)) I will allocate each of the cabin=NaN values to one of the available cabins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df2 = load()\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     print(df2[(~df2['cabin'].isnull()) & (df2['cabin'].str.contains(''))][['pclass','fare','cabin']])\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "#     print(df2[(df2['cabin'].isnull().values.any() & (df2['cabin'].str.contains('A')))]['fare'])\n",
    "\n",
    "# df2[(df2['cabin'].isnull().values.any()) \\\n",
    "#     & (df2['cabin'].str.contains('A'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cabin_letters=['cabin_A', 'cabin_B', 'cabin_C', 'cabin_D', 'cabin_E', 'cabin_F', 'cabin_G']\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     df3 = df2[(~df2['cabin'].isnull()) & (df2['pclass']==1)][['cabin_A', 'cabin_B', 'cabin_C', 'cabin_D', 'cabin_E', 'cabin_F', 'cabin_G','pclass','fare']].sort_values('fare')\n",
    "#     #print(df3.sum())\n",
    "#     #print(df3[df3.fare > 20].sum())\n",
    "#     print(df2[df2.pclass ==1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating cabin column into cabin_letter and cabin_number\n",
    "cabin_letters=['A','B','C','D','E','F','G']\n",
    "for letter in cabin_letters:\n",
    "    df2[f'cabin_{letter}'] = df2['cabin'].apply(lambda x: type(x)==type('') and letter in x) #1\n",
    "    df2[f'cabin_{letter}'] = df2[f'cabin_{letter}'].astype(int)\n",
    "df2['cabin_number'] = df2['cabin'].apply(lambda x: re.findall(r'[0-9]+', x) if type(x)==type('') else [np.nan]) #2\n",
    "df2['cabin_number'] = df2['cabin_number'].apply(lambda x: x[0] if len(x)>0 else np.nan) #3\n",
    "\n",
    "#1: loop is creating new colums cabin_A,...,cabin_F\n",
    "# - lambda x: type(x)==type(''): sets the entries of df2['cabin'] to be strings\n",
    "# - and letter in x: sets the letter in x to a 1 in the corresponding column_letter column\n",
    "\n",
    "#2: creating new column cabin_number\n",
    "# - lambda x: re.findall(r'[0-9]+', x) creates a list of the numbers separated by spaces\n",
    "# - if type(x)==type(''): restricts lambda function to only the non-NaN values, else keep it as NaN\n",
    "\n",
    "#3: sets the values in cabin_number that have multiple entries e.g. [23, 25, 27] to the first value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21            D56\n",
      "23             A6\n",
      "27    C23 C25 C27\n",
      "Name: cabin, dtype: object\n",
      "21            [56]\n",
      "23             [6]\n",
      "27    [23, 25, 27]\n",
      "Name: cabin, dtype: object\n",
      "21            D56\n",
      "23             A6\n",
      "27    C23 C25 C27\n",
      "Name: cabin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df5 = df2[~df2['cabin'].isnull()]['cabin'][5:8]\n",
    "print(df5)\n",
    "print(df5.apply(lambda x: re.findall(r'[0-9]+', x) if type(x)==type('') else [np.nan,]))\n",
    "print(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of fares for the entries cabin=NaN \n",
    "# df2[pd.isnull(df2['cabin'])]['fare'].hist(bins=np.arange(0,175,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of fares for the entries with cabin != NaN and cabin\n",
    "# df2[(df2['cabin'].isnull().values.any()) \\\n",
    "#     & (df2['cabin'].str.contains('A'))]['fare'].hist(bins=np.arange(0,200,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
